import torch
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision import datasets
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
from google.colab import drive
from PIL import Image

drive.mount('/content/drive')

# Define transformation pipeline
transform = transforms.Compose([
    #transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load datasets
train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/dataset/train', transform=transform)
test_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/dataset/test', transform=transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)



# Load VGG-16 model and modify for custom classification task
model = models.vgg16(pretrained=True)

# Freeze the parameters of the feature extractor layers
for param in model.features.parameters():
    param.requires_grad = False

# Adjust classifier for the number of classes
num_classes = len(train_dataset.classes)
model.classifier = nn.Sequential(
    nn.Linear(25088, 128),
    nn.ReLU(),
    nn.Dropout(0.1),
    nn.Linear(128, num_classes)
)

# Move the model to GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Define training metrics
train_losses = []
train_accuracies = []
train_precisions = []
train_recalls = []
train_f1_scores = []

num_epochs = 20  # Number of epochs for training

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    correct_train = 0
    total_train = 0
    all_train_labels, all_train_preds = [], []

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs.data, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()
        all_train_labels.extend(labels.cpu().numpy())
        all_train_preds.extend(predicted.cpu().numpy())

    # Record metrics
    train_losses.append(running_loss / len(train_loader))
    train_accuracies.append(100 * correct_train / total_train)
    train_precisions.append(precision_score(all_train_labels, all_train_preds, average='weighted'))
    train_recalls.append(recall_score(all_train_labels, all_train_preds, average='weighted'))
    train_f1_scores.append(f1_score(all_train_labels, all_train_preds, average='weighted'))

    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_losses[-1]:.4f}, Accuracy: {train_accuracies[-1]:.2f}, '
          f'Precision: {train_precisions[-1]:.2f}, Recall: {train_recalls[-1]:.2f}, F1-Score: {train_f1_scores[-1]:.2f}')


# Plot training metrics
plt.figure(figsize=(12, 6))
epochs = list(range(1, num_epochs + 1))

plt.plot(epochs, train_losses, label='Training Loss', color='blue')
normalized_train_accuracies = [acc / 100 for acc in train_accuracies]
plt.plot(epochs, normalized_train_accuracies, label='Training Accuracy', color='green', linestyle='--')
plt.plot(epochs, train_precisions, label='Training Precision', color='purple', linestyle=':')
plt.plot(epochs, train_recalls, label='Training Recall', color='cyan', linestyle=':')
plt.plot(epochs, train_f1_scores, label='Training F1-Score', color='red', linestyle='-.')
plt.title('Training Loss, Accuracy, Precision, Recall, and F1-Score')
plt.xlabel('Epochs')
plt.ylabel('Values')
plt.legend()
plt.grid()
plt.savefig('/content/drive/MyDrive/dataset/train_metrics_curves.png', bbox_inches='tight')
plt.show()

# Evaluate on test set
model.eval()
correct = 0
total = 0
all_labels, all_preds = [], []
misclassified_images = []
misclassified_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)

        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(predicted.cpu().numpy())

        # Collect misclassified images
        for i in range(images.size(0)):
            if predicted[i] != labels[i]:
                misclassified_images.append(images[i].cpu())
                misclassified_labels.append((labels[i].cpu().item(), predicted[i].cpu().item()))

# Compute metrics
accuracy = 100 * correct / total
precision = precision_score(all_labels, all_preds, average='weighted')
recall = recall_score(all_labels, all_preds, average='weighted')
f1 = f1_score(all_labels, all_preds, average='weighted')
cm = confusion_matrix(all_labels, all_preds)

print(f'Accuracy: {accuracy:.2f}%, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}')

# Display misclassified images
for i, (image, (true_label, pred_label)) in enumerate(zip(misclassified_images[:10], misclassified_labels)):
    plt.imshow(np.transpose(image.numpy(), (1, 2, 0)))
    plt.title(f'Actual: {train_dataset.classes[true_label]}, Predicted: {train_dataset.classes[pred_label]}')
    plt.axis('off')
    plt.show()

# Display confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.classes)
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.savefig('/content/drive/MyDrive/dataset/confusion_matrix.png', bbox_inches='tight')
plt.show()

torch.save(model.state_dict(), '/content/drive/MyDrive/dataset/vgg16_model.pth')




